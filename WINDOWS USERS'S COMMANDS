NAS D WINDOWS HANTOMA:

Here is the same `README.md` file, but with the "How to Run Locally" section updated to include instructions for **Windows users**.

-----

````markdown
# üöÄ Social Media Analytics Pipeline

### A Project by Soulaymane Boulaich (1st Year Big Data & AI Engineering)

Hey everyone!

As first-year students in **Big Data and AI**, I wanted to build a project that combines both of our core subjects. This project isn't just one simple script‚Äîit's a complete, **end-to-end data system** that does the job of a real data engineer and AI specialist.

---

## 1. The "Big Data" Part: The ETL Pipeline

The foundation of this project is a real **ETL (Extract, Transform, Load) pipeline**.

* **Extract:** The pipeline connects to multiple, live APIs (Reddit, Twitter/X, and YouTube) to pull in messy, raw data (posts, tweets, and comments).
* **Transform:** It then uses `pandas` to clean, process, and standardize all this different data into one clean, useful format.
* **Load:** Finally, it loads all the processed data into a central `SQLite` database, ready for analysis.

## 2. The "AI" Part: The Analysis Engine

This is where we add the intelligence. The pipeline takes the clean text and uses **Natural Language Processing (NLP)** to understand it.

* **Sentiment Analysis:** It uses AI models (`VADER` and a custom-trained `scikit-learn` model) to read the text and classify its emotion as positive, negative, or neutral.
* **Topic Modeling & NER:** It also uses `spaCy` and `NLTK` to automatically discover the main topics being discussed and find the most mentioned people and organizations.

## 3. The Result: An Interactive Dashboard

All this data is useless if you can't see it. The final piece is a **web dashboard** built with `Plotly Dash`. It reads directly from our database and lets you:
* Visualize all the insights in real-time.
* Filter the data by platform (Reddit, Twitter, etc.).
* Select a date range to see trends.

This project shows the complete journey: from messy, raw data on the internet to a clean, intelligent, and interactive dashboard.

---

## üíª Tech Stack

* **Data Collection:** `praw` (Reddit), `tweepy` (Twitter), `google-api-python-client` (YouTube)
* **Data Processing:** `pandas`
* **NLP/ML:** `scikit-learn`, `spacy`, `nltk`, `vaderSentiment`, `joblib`
* **Database:** `sqlite3`
* **Dashboard:** `Plotly Dash`
* **Automation:** `schedule`
* **Deployment:** `gunicorn`

---

## üèÉ‚Äç‚ôÇÔ∏è How to Run Locally (Windows Guide)

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your_username/your_project_name.git](https://github.com/your_username/your_project_name.git)
    cd your_project_name
    ```
2.  **Create and activate environment:**
    (Open Command Prompt, not PowerShell)
    ```cmd
    :: Create the environment
    python -m venv venv

    :: Activate the environment
    venv\Scripts\activate.bat
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Download NLP models:**
    ```bash
    python -m spacy download en_core_web_sm
    python -c "import nltk; nltk.download('stopwords'); nltk.download('vader_lexicon')"
    ```
5.  **Create your `.env` file:**
    * Create a file named `.env` (you can do this in VS Code or any text editor) and add your API keys:
    ```
    REDDIT_CLIENT_ID=your_client_id_here
    REDDIT_CLIENT_SECRET=your_secret_here
    REDDIT_USER_AGENT=MyAnalyticsApp/1.0
    TWITTER_BEARER_TOKEN=your_bearer_token_here
    YOUTUBE_API_KEY=your_google_api_key_here
    ```
6.  **(Optional) Train the custom model:**
    * Download the Sentiment140 dataset from Kaggle, name it `training_data.csv`.
    * Run:
    ```bash
    python train_model.py
    ```
7.  **Run the pipeline (to get data):**
    ```bash
    python pipeline.py
    ```
    *(Let it run once, then stop with Ctrl+C)*
8.  **Run the dashboard:**
    ```bash
    python dashboard.py
    ```
    * Visit `http://127.0.0.1:8050` in your browser.

---

## üöß API Limitations (Facebook/Instagram)

* Access to the Facebook and Instagram APIs is highly restricted by Meta.
* It requires a formal Business Verification and an App Review process.
* This is not feasible for personal or academic projects, as approval is almost exclusively granted to registered businesses for commercial purposes.
````
